{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a488cc06",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from constants import CFB26_ATTRS, CROP_LOCATIONS, GOING_RIGHT_PATHS\n",
    "\n",
    "\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98a35a6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def show_image_plt(image:np.array):\n",
    "    image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    fig, ax = plt.subplots(figsize=(20, 16))\n",
    "    ax.imshow(image_rgb)\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def show_image_with_box(image_path, x, y, w, h, alpha=0.15):\n",
    "    image = cv2.imread(image_path)\n",
    "    image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    fig, ax = plt.subplots(figsize=(10*3, 8*3))\n",
    "    ax.imshow(image_rgb)\n",
    "\n",
    "    # Transparent rectangle\n",
    "    rect = patches.Rectangle((x, y), w, h,\n",
    "                             linewidth=2,\n",
    "                             edgecolor='yellow',\n",
    "                             facecolor='yellow',\n",
    "                             alpha=alpha)\n",
    "    ax.add_patch(rect)\n",
    "    ax.set_title(f\"Box: (x={x}, y={y}, w={w}, h={h})\")\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "\n",
    "# path = \"/Users/brianpennington/git/cfb/capture_stream/mnt/cfb_shared/screenshots/frame_20250802_171000_000049.jpg\"\n",
    "path = \"/Users/brianpennington/git/cfb/capture_stream/mnt/cfb_shared/screenshots/frame_20250804_004207_000000.jpg\"\n",
    "# rect_locs = CROP_LOCATIONS['SCORES_SCHEDULE']['table_data']\n",
    "CROP_LOCATIONS = {\n",
    "    'SCORES_SCHEDULE': {\n",
    "        'page_title': {'x': 40, 'y': 20, 'w': 500, 'h': 40},\n",
    "        'table_data': {'x': 60, 'y': 265, 'w': 860, 'h': 349},\n",
    "    }\n",
    "}\n",
    "rect_locs = CROP_LOCATIONS['SCORES_SCHEDULE']['page_title']\n",
    "show_image_with_box(path, **rect_locs)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31ed3297",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def show_image_with_box(image_path, crop_locations, alpha=0.15):\n",
    "    image = cv2.imread(image_path)\n",
    "    image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    fig, ax = plt.subplots(figsize=(10*3, 8*3))\n",
    "    ax.imshow(image_rgb)\n",
    "\n",
    "    for label, coords in crop_locations.items(): #CROP_LOCATIONS['SCORES_SCHEDULE'].items():\n",
    "        x, y, w, h = coords['x'], coords['y'], coords['w'], coords['h']\n",
    "        rect = patches.Rectangle((x, y), w, h, linewidth=2, edgecolor=d_colors[label], facecolor='none', label=label)\n",
    "        ax.add_patch(rect)\n",
    "        ax.text(x, y - 5, label, color=d_colors[label], fontsize=9)\n",
    "\n",
    "    # Transparent rectangle\n",
    "    # rect = patches.Rectangle((x, y), w, h,\n",
    "    #                          linewidth=2,\n",
    "    #                          edgecolor='yellow',\n",
    "    #                          facecolor='yellow',\n",
    "    #                          alpha=alpha)\n",
    "    # ax.add_patch(rect)\n",
    "    # ax.set_title(f\"Box: (x={x}, y={y}, w={w}, h={h})\")\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "    \n",
    "\n",
    "\n",
    "d_colors = {\n",
    "    'page_title': 'lightblue',\n",
    "    'table_data': 'green',\n",
    "    'left_trigger': 'orange',\n",
    "    'left_trigger': 'orange',\n",
    "    'right_trigger': 'pink'\n",
    "}\n",
    "CROP_LOCATIONS = {\n",
    "    'SCORES_SCHEDULE': {\n",
    "        'page_title': {'x': 40, 'y': 20, 'w': 500, 'h': 40},\n",
    "        'table_data': {'x': 60, 'y': 200, 'w': 860, 'h': 414},\n",
    "        'left_trigger': {'x': 93, 'y': 126, 'w': 210, 'h': 24},\n",
    "        'right_trigger': {'x': 675, 'y': 126, 'w': 210, 'h': 24},\n",
    "    }\n",
    "}\n",
    "\n",
    "    \n",
    "show_image_with_box(path, CROP_LOCATIONS['SCORES_SCHEDULE'])\n",
    "\n",
    "\n",
    "# fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "\n",
    "# # Loop over each box in SCORES_SCHEDULE\n",
    "# for label, coords in boxes['SCORES_SCHEDULE'].items():\n",
    "#     x, y, w, h = coords['x'], coords['y'], coords['w'], coords['h']\n",
    "#     rect = patches.Rectangle((x, y), w, h, linewidth=2, edgecolor=d_colors[label], facecolor='none', label=label)\n",
    "#     ax.add_patch(rect)\n",
    "#     ax.text(x, y - 5, label, color=d_colors[label], fontsize=9)\n",
    "\n",
    "# # Adjust axes\n",
    "# ax.set_xlim(0, 1000)\n",
    "# ax.set_ylim(0, 700)\n",
    "# ax.invert_yaxis()  # Invert if origin is top-left like in image coordinates\n",
    "# plt.title(\"Box Annotations from SCORES_SCHEDULE\")\n",
    "# plt.grid(True)\n",
    "# plt.legend()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb17a088",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import easyocr\n",
    "\n",
    "\n",
    "def crop_region(image_input, x, y, w, h):\n",
    "    if isinstance(image_input, str):\n",
    "        image = cv2.imread(image_input)\n",
    "    elif isinstance(image_input, np.ndarray):\n",
    "        image = image_input\n",
    "    else:\n",
    "        raise TypeError(\"image_input must be a filepath (str) or a numpy.ndarray\")\n",
    "    \n",
    "    cropped = image[y:y+h, x:x+w]\n",
    "    return cropped\n",
    "\n",
    "def preprocess_image(image_input):\n",
    "    if isinstance(image_input, str):\n",
    "        image = cv2.imread(image_input)\n",
    "    elif isinstance(image_input, np.ndarray):\n",
    "        image = image_input\n",
    "    else:\n",
    "        raise TypeError(\"image_input must be a filepath (str) or a numpy.ndarray\")\n",
    "    \n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Optional: increase contrast or sharpen\n",
    "    blur = cv2.GaussianBlur(gray, (3, 3), 0)\n",
    "    thresh = cv2.adaptiveThreshold(blur, 255,\n",
    "                                    cv2.ADAPTIVE_THRESH_GAUSSIAN_C,\n",
    "                                    cv2.THRESH_BINARY_INV, 11, 2)\n",
    "    return thresh\n",
    "\n",
    "def enhance_contrast(image):\n",
    "    \"\"\"Apply CLAHE to enhance local contrast.\"\"\"\n",
    "    lab = cv2.cvtColor(image, cv2.COLOR_BGR2LAB)\n",
    "    l, a, b = cv2.split(lab)\n",
    "\n",
    "    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))\n",
    "    cl = clahe.apply(l)\n",
    "\n",
    "    merged = cv2.merge((cl, a, b))\n",
    "    result = cv2.cvtColor(merged, cv2.COLOR_LAB2BGR)\n",
    "    return result\n",
    "\n",
    "def denoise_image(image):\n",
    "    \"\"\"Apply bilateral filter for edge-preserving denoising.\"\"\"\n",
    "    return cv2.bilateralFilter(image, d=9, sigmaColor=75, sigmaSpace=75)\n",
    "\n",
    "def run_easyocr_on_image(image_path, use_gpu=True, preprocess=False, show_image=False, denoise=False, enhance_contrast=False, crop_loc=None):\n",
    "    image_input = image_path\n",
    "    reader = easyocr.Reader(['en'], gpu=use_gpu)\n",
    "\n",
    "    if preprocess:\n",
    "        image_input = preprocess_image(image_input)\n",
    "    if crop_loc is not None:\n",
    "        image_input = crop_region(image_input, **crop_loc)\n",
    "\n",
    "    if denoise:\n",
    "        image_input = denoise_image(image_input)\n",
    "    if enhance_contrast:\n",
    "        image_input = enhance_contrast(image_input)\n",
    "    image_input = cv2.resize(image_input, None, fx=2, fy=2, interpolation=cv2.INTER_CUBIC)\n",
    "\n",
    "    if show_image == True:\n",
    "        show_image_plt(image_input)\n",
    "\n",
    "    results = reader.readtext(image_input)\n",
    "    # for bbox, text, conf in results:\n",
    "    #     print(f\"{text} ({conf:.2f}) | {bbox}\")\n",
    "    return results\n",
    "\n",
    "\n",
    "path = \"/Users/brianpennington/git/cfb/capture_stream/mnt/cfb_shared/screenshots/frame_20250802_171000_000049.jpg\"\n",
    "\n",
    "data = run_easyocr_on_image(\n",
    "    image_path = path, \n",
    "    use_gpu = False, \n",
    "    preprocess = False, \n",
    "    denoise = False,\n",
    "    enhance_contrast = False,\n",
    "    show_image = False,\n",
    "    crop_loc = CROP_LOCATIONS['ROSTER']['table_data']\n",
    ")\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11c88e16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import json\n",
    "# import numpy as np\n",
    "# import pandas as pd\n",
    "# from collections import defaultdict\n",
    "\n",
    "# def vertical_center(bbox):\n",
    "#     return sum(p[1] for p in bbox) / 4\n",
    "\n",
    "\n",
    "# def group_ocr_rows(data, y_tolerance=10):\n",
    "#     rows = defaultdict(list)\n",
    "#     for bbox, text, conf in data:\n",
    "#         y_center = vertical_center(bbox)\n",
    "#         found = False\n",
    "#         for key in rows:\n",
    "#             if abs(key - y_center) < y_tolerance:\n",
    "#                 rows[key].append((bbox, text))\n",
    "#                 found = True\n",
    "#                 break\n",
    "#         if not found:\n",
    "#             rows[y_center].append((bbox, text))\n",
    "#     # Sort rows vertically\n",
    "#     sorted_rows = [rows[k] for k in sorted(rows)]\n",
    "#     return sorted_rows\n",
    "\n",
    "\n",
    "\n",
    "# path = \"/Users/brianpennington/git/cfb/capture_stream/mnt/cfb_shared/screenshots/frame_20250802_171000_000049.jpg\"\n",
    "# data = run_easyocr_on_image(\n",
    "#     image_path = path, \n",
    "#     use_gpu = False, \n",
    "#     preprocess = False, \n",
    "#     show_image = True,\n",
    "#     crop_loc = roster_data_loc\n",
    "# )\n",
    "\n",
    "# headers = [d[1] for d in data if d[0][0][1] <= 30]\n",
    "# body_data = [d for d in data if d[0][0][1] > 30]\n",
    "# grouped_rows = group_ocr_rows(body_data)\n",
    "# print(grouped_rows[:2])\n",
    "# rows = [row[1] for row in grouped_rows[0]]\n",
    "# print(json.dumps(rows, indent=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2627b34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def build_table(headers, grouped_rows):\n",
    "#     table = []\n",
    "#     for row in grouped_rows:\n",
    "#         # Sort left to right by bbox X-coordinate\n",
    "#         sorted_row = sorted(row, key=lambda x: x[0][0][0])\n",
    "#         row_text = [t[1] for t in sorted_row]\n",
    "\n",
    "#         if len(row_text) == len(headers):\n",
    "#             table.append(row_text)\n",
    "#         else:\n",
    "#             table.append([np.nan] * len(headers))\n",
    "#     return pd.DataFrame(table, columns=headers)\n",
    "\n",
    "# grouped_rows = group_ocr_rows(body_data)\n",
    "# df_49 = build_table(headers, grouped_rows)\n",
    "# print(df_49)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbe5947e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "grouped_rows = group_ocr_rows(body_data)\n",
    "df = build_table(headers, grouped_rows)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e365d3e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "file = \"/Users/brianpennington/git/cfb/capture_stream/mnt/cfb_shared/screenshots/frame_20250802_170956_000033.jpg\"\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "folder = Path(\"/Users/brianpennington/git/cfb/capture_stream/mnt/cfb_shared/screenshots/\")\n",
    "\n",
    "paths = []\n",
    "for file in folder.iterdir():\n",
    "    if file.is_file():\n",
    "        path = str(file)\n",
    "        if path[-7:] != \"log.csv\":\n",
    "            # print(file.resolve())\n",
    "            paths.append(path)\n",
    "paths = sorted(paths)\n",
    "print(f\"paths(len={len(paths)}) = {paths}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2ecd84c",
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_cols = ['OVR', 'SPD', 'ACC', 'AGI', 'COD', 'STR', 'AWR', 'THP', 'SAC', 'MAC']\n",
    "\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "from scipy.spatial.distance import euclidean\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def vertical_center(bbox):\n",
    "    return sum(p[1] for p in bbox) / 4\n",
    "\n",
    "\n",
    "def group_ocr_rows(data, y_tolerance=10):\n",
    "    rows = defaultdict(list)\n",
    "    for bbox, text, conf in data:\n",
    "        y_center = vertical_center(bbox)\n",
    "        found = False\n",
    "        for key in rows:\n",
    "            if abs(key - y_center) < y_tolerance:\n",
    "                rows[key].append((bbox, text))\n",
    "                found = True\n",
    "                break\n",
    "        if not found:\n",
    "            rows[y_center].append((bbox, text))\n",
    "    # Sort rows vertically\n",
    "    sorted_rows = [rows[k] for k in sorted(rows)]\n",
    "    return sorted_rows\n",
    "\n",
    "\n",
    "\n",
    "def build_table(headers, grouped_rows):\n",
    "    table = []\n",
    "    for row in grouped_rows:\n",
    "        # Sort left to right by bbox X-coordinate\n",
    "        sorted_row = sorted(row, key=lambda x: x[0][0][0])\n",
    "        row_text = [t[1] for t in sorted_row]\n",
    "\n",
    "        if len(row_text) == len(headers):\n",
    "            table.append(row_text)\n",
    "        else:\n",
    "            table.append([np.nan] * len(headers))\n",
    "    return pd.DataFrame(table, columns=headers)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def row_fingerprint(row, cols):\n",
    "    fp = []\n",
    "    for col in cols:\n",
    "        val = row.get(col)\n",
    "        if pd.notna(val):\n",
    "            try:\n",
    "                fp.append(float(val))\n",
    "            except ValueError:\n",
    "                continue  # skip if value is not numeric\n",
    "    return tuple(fp)\n",
    "\n",
    "\n",
    "def fingerprint_similarity(f1, f2):\n",
    "    if len(f1) != len(f2):\n",
    "        return float('inf')  # avoid comparing rows with different lengths\n",
    "    return euclidean(f1, f2)\n",
    "\n",
    "def align_frames(df_prev, df_curr, numeric_cols, max_distance=5.0):\n",
    "    matched_rows = []\n",
    "    used_prev_indices = set()\n",
    "\n",
    "    for i, curr_row in df_curr.iterrows():\n",
    "        if curr_row.isnull().all():\n",
    "            matched_rows.append((None, i))  # missing row\n",
    "            continue\n",
    "\n",
    "        curr_fp = row_fingerprint(curr_row, numeric_cols)\n",
    "        best_match = None\n",
    "        best_score = float('inf')\n",
    "        best_j = None\n",
    "\n",
    "        for j, prev_row in df_prev.iterrows():\n",
    "            if j in used_prev_indices or prev_row.isnull().all():\n",
    "                continue\n",
    "            prev_fp = row_fingerprint(prev_row, numeric_cols)\n",
    "            score = fingerprint_similarity(curr_fp, prev_fp)\n",
    "\n",
    "            if score < best_score and score <= max_distance:\n",
    "                best_score = score\n",
    "                best_j = j\n",
    "                best_match = prev_row\n",
    "\n",
    "        if best_j is not None:\n",
    "            used_prev_indices.add(best_j)\n",
    "            matched_rows.append((best_j, i))\n",
    "        else:\n",
    "            matched_rows.append((None, i))\n",
    "\n",
    "    return matched_rows\n",
    "\n",
    "def merge_frames(df_prev, df_curr, numeric_cols):\n",
    "    alignment = align_frames(df_prev, df_curr, numeric_cols)\n",
    "    print(f\"len(alignment) = {len(alignment)}\")\n",
    "    merged = []\n",
    "\n",
    "    used_prev_indices = set()\n",
    "    used_curr_indices = set()\n",
    "\n",
    "    # First: merge aligned rows\n",
    "    for prev_idx, curr_idx in alignment:\n",
    "        if prev_idx is not None:\n",
    "            used_prev_indices.add(prev_idx)\n",
    "        if curr_idx is not None:\n",
    "            used_curr_indices.add(curr_idx)\n",
    "\n",
    "        if prev_idx is None:\n",
    "            merged.append(df_curr.iloc[curr_idx])\n",
    "        else:\n",
    "            row = df_curr.iloc[curr_idx].combine_first(df_prev.iloc[prev_idx])\n",
    "            merged.append(row)\n",
    "\n",
    "    # Second: append any unmatched rows from df_prev\n",
    "    for idx in df_prev.index:\n",
    "        if idx not in used_prev_indices:\n",
    "            merged.append(df_prev.iloc[idx])\n",
    "\n",
    "    return pd.DataFrame(merged, columns=df_curr.columns)\n",
    "\n",
    "def merge_frames_list(df_list, numeric_cols, max_distance=5.0, match_window=10):\n",
    "    merged_rows = []\n",
    "\n",
    "    for i, df in enumerate(df_list):\n",
    "        if i == 0:\n",
    "            merged_rows.extend(df.to_dict('records'))\n",
    "            continue\n",
    "\n",
    "        for _, row in df.iterrows():\n",
    "            if row.isnull().all():\n",
    "                continue\n",
    "\n",
    "            row_fp = row_fingerprint(row, numeric_cols)\n",
    "            found_match = False\n",
    "\n",
    "            # Only search in last N rows\n",
    "            search_start = max(0, len(merged_rows) - match_window)\n",
    "            for existing_row in merged_rows[search_start:]:\n",
    "                existing_fp = row_fingerprint(existing_row, numeric_cols)\n",
    "                score = fingerprint_similarity(row_fp, existing_fp)\n",
    "\n",
    "                if score <= max_distance:\n",
    "                    found_match = True\n",
    "                    break\n",
    "\n",
    "            if not found_match:\n",
    "                merged_rows.append(row.to_dict())\n",
    "\n",
    "    return pd.DataFrame(merged_rows)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "df_combined = merge_frames_list(arr_dfs, numeric_cols)\n",
    "df_combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9d43099",
   "metadata": {},
   "outputs": [],
   "source": [
    "arr_dfs_going_right = []\n",
    "# path_arr = paths[25:50]\n",
    "\n",
    "\n",
    "for i, path in enumerate(GOING_RIGHT_PATHS[:6]):\n",
    "    print(f\"path = {path}\")\n",
    "    # path = \"/Users/brianpennington/git/cfb/capture_stream/mnt/cfb_shared/screenshots/frame_20250802_171000_000049.jpg\"\n",
    "    data = run_easyocr_on_image(\n",
    "        image_path = path, \n",
    "        use_gpu = False, \n",
    "        preprocess = False, \n",
    "        show_image = False,\n",
    "        crop_loc = roster_data_loc\n",
    "    )\n",
    "\n",
    "    headers = [d[1] for d in data if d[0][0][1] <= 30]\n",
    "    body_data = [d for d in data if d[0][0][1] > 30]\n",
    "    grouped_rows = group_ocr_rows(body_data)\n",
    "    df = build_table(headers, grouped_rows)\n",
    "    arr_dfs_going_right.append(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1705ee40",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial.distance import euclidean\n",
    "\n",
    "\n",
    "def merge_columns_from_frame_going_right(master_df, new_df, max_distance=5.0):\n",
    "    \n",
    "    match_cols = master_df.columns.tolist()[-3:]\n",
    "\n",
    "    def row_fingerprint(row):\n",
    "        fp = []\n",
    "        for col in match_cols:\n",
    "            val = row.get(col)\n",
    "            if pd.notna(val):\n",
    "                try:\n",
    "                    fp.append(float(val))\n",
    "                except ValueError:\n",
    "                    continue\n",
    "        return tuple(fp)\n",
    "\n",
    "    def similarity(fp1, fp2):\n",
    "        if len(fp1) != len(fp2):\n",
    "            return float('inf')\n",
    "        return euclidean(fp1, fp2)\n",
    "\n",
    "    # Add new columns to master_df if needed\n",
    "    columns = []\n",
    "    for col in new_df.columns:\n",
    "        if col in CFB26_ATTRS:\n",
    "            if col not in master_df.columns:\n",
    "                master_df[col] = np.nan\n",
    "            columns.append(col)\n",
    "        else:\n",
    "            print(f\"col = {col} not in CFB26_ATTRS\")\n",
    "\n",
    "    new_df = new_df[columns]\n",
    "    # Match each row in new_df to a row in master_df\n",
    "    for _, new_row in new_df.iterrows():\n",
    "        new_fp = row_fingerprint(new_row)\n",
    "\n",
    "        best_match = None\n",
    "        best_dist = float('inf')\n",
    "        for idx, master_row in master_df.iterrows():\n",
    "            master_fp = row_fingerprint(master_row)\n",
    "            dist = similarity(new_fp, master_fp)\n",
    "            if dist < best_dist and dist <= max_distance:\n",
    "                best_dist = dist\n",
    "                best_match = idx\n",
    "\n",
    "        if best_match is not None:\n",
    "            for col in new_df.columns:\n",
    "                val = new_row[col]\n",
    "                if pd.notna(val):\n",
    "                    master_df.at[best_match, col] = val\n",
    "\n",
    "    return master_df\n",
    "\n",
    "# match_cols = ['THP', 'SAC', 'MAC']  # stable columns\n",
    "merged_df = arr_dfs_going_right[0].copy(deep=True)\n",
    "print(f\"merged_df.columns = {merged_df.columns}\")\n",
    "for i in range(1, len(arr_dfs_going_right)):\n",
    "    merged_df = merge_columns_from_frame_going_right(\n",
    "        master_df=merged_df,\n",
    "        new_df=arr_dfs_going_right[i],\n",
    "        max_distance=5.0\n",
    "    )\n",
    "\n",
    "# merged_rows = merge_columns_from_frame(merged_rows, new_df, match_cols)\n",
    "merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17d03d0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_columns_from_frame_going_left(master_df, new_df, max_distance=5.0):\n",
    "    # match_cols = master_df.columns.tolist()[:3]  # left-most stable cols\n",
    "\n",
    "    def row_fingerprint(row):\n",
    "        fp = []\n",
    "        for col in match_cols:\n",
    "            val = row.get(col)\n",
    "            if pd.notna(val):\n",
    "                try:\n",
    "                    fp.append(float(val))\n",
    "                except ValueError:\n",
    "                    continue\n",
    "        return tuple(fp)\n",
    "\n",
    "    def similarity(fp1, fp2):\n",
    "        if len(fp1) != len(fp2):\n",
    "            return float('inf')\n",
    "        return euclidean(fp1, fp2)\n",
    "\n",
    "    # Filter to valid columns\n",
    "    new_cols = []\n",
    "    for col in new_df.columns:\n",
    "        if col in CFB26_ATTRS:\n",
    "            if col not in master_df.columns:\n",
    "                master_df.insert(loc=0, column=col, value=np.nan)\n",
    "            else:\n",
    "                if (len(match_cols) < 3) and (col.upper() not in ['NAME', 'YEAR']):\n",
    "                    match_cols.append(col)\n",
    "            new_cols.append(col)\n",
    "        else:\n",
    "            print(f\"col = {col} not in CFB26_ATTRS\")\n",
    "\n",
    "    new_df = new_df[new_cols]\n",
    "\n",
    "    for _, new_row in new_df.iterrows():\n",
    "        new_fp = row_fingerprint(new_row)\n",
    "        best_idx = None\n",
    "        best_dist = float('inf')\n",
    "        for idx, master_row in master_df.iterrows():\n",
    "            master_fp = row_fingerprint(master_row)\n",
    "            dist = similarity(new_fp, master_fp)\n",
    "            if dist < best_dist and dist <= max_distance:\n",
    "                best_dist = dist\n",
    "                best_idx = idx\n",
    "\n",
    "        if best_idx is not None:\n",
    "            for col in new_df.columns:\n",
    "                val = new_row[col]\n",
    "                if pd.notna(val):\n",
    "                    master_df.at[best_idx, col] = val\n",
    "\n",
    "    return master_df\n",
    "\n",
    "# Scrolling left\n",
    "arr_dfs_going_left = arr_dfs_going_right[::-1]\n",
    "merged_df_going_left = arr_dfs_going_left[0].copy(deep=True)\n",
    "for df in arr_dfs_going_left:\n",
    "    merged_df_going_left = merge_columns_from_frame_going_left(\n",
    "        master_df=merged_df_going_left,\n",
    "        new_df=df,\n",
    "        max_distance=5.0\n",
    "    )\n",
    "\n",
    "merged_df_going_left\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43a052bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(arr_dfs_going_left[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f87111af",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(arr_dfs_going_left[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cda238b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def sad(a, b):\n",
    "    return np.nansum(np.abs(a - b))\n",
    "\n",
    "def detect_scroll_shift(prev_df, curr_df, numeric_cols, max_shift=5):\n",
    "\n",
    "    shared_cols = [col for col in numeric_cols if col in prev_df.columns and col in curr_df.columns]\n",
    "    prev = prev_df[shared_cols].astype(np.float32).values\n",
    "    curr = curr_df[shared_cols].astype(np.float32).values\n",
    "\n",
    "    best_score = float('inf')\n",
    "    best_shift = (0, 0)\n",
    "\n",
    "    for row_shift in range(-max_shift, max_shift + 1):\n",
    "        for col_shift in range(-max_shift, max_shift + 1):\n",
    "            # Define slice ranges\n",
    "            r1s, r1e = max(0, row_shift), min(prev.shape[0], curr.shape[0] + row_shift)\n",
    "            r2s, r2e = max(0, -row_shift), min(curr.shape[0], prev.shape[0] - row_shift)\n",
    "\n",
    "            c1s, c1e = max(0, col_shift), min(prev.shape[1], curr.shape[1] + col_shift)\n",
    "            c2s, c2e = max(0, -col_shift), min(curr.shape[1], prev.shape[1] - col_shift)\n",
    "\n",
    "            if r1e - r1s <= 2 or c1e - c1s <= 2:\n",
    "                continue  # skip if not enough overlap to compare\n",
    "\n",
    "            prev_slice = prev[r1s:r1e, c1s:c1e]\n",
    "            curr_slice = curr[r2s:r2e, c2s:c2e]\n",
    "\n",
    "            score = sad(prev_slice, curr_slice)\n",
    "\n",
    "            if score < best_score:\n",
    "                best_score = score\n",
    "                best_shift = (row_shift, col_shift)\n",
    "\n",
    "    return best_shift, best_score\n",
    "\n",
    "\n",
    "numeric_cols = ['OVR', 'SPD', 'ACC', 'AGI', 'COD', 'STR', 'AWR', 'THP', 'SAC', 'MAC', 'DAC', 'RUN', 'TUP', 'BSK']\n",
    "shift, score = detect_scroll_shift(arr_dfs_going_left[0], arr_dfs_going_left[2], numeric_cols, max_shift=5)\n",
    "print(f\"Detected scroll: rows={shift[0]}, cols={shift[1]} | score={score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cef71cb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_rows_from_frame_going_up(master_df, new_df, match_cols, max_distance=5.0):\n",
    "    from scipy.spatial.distance import euclidean\n",
    "\n",
    "    def row_fingerprint(row):\n",
    "        return tuple(float(row.get(c)) for c in match_cols if pd.notna(row.get(c)))\n",
    "\n",
    "    def similarity(fp1, fp2):\n",
    "        if len(fp1) != len(fp2):\n",
    "            return float('inf')\n",
    "        return euclidean(fp1, fp2)\n",
    "\n",
    "    unmatched_new_rows = []\n",
    "\n",
    "    for _, new_row in new_df.iterrows():\n",
    "        new_fp = row_fingerprint(new_row)\n",
    "        matched = False\n",
    "\n",
    "        for _, master_row in master_df.iterrows():\n",
    "            master_fp = row_fingerprint(master_row)\n",
    "            dist = similarity(new_fp, master_fp)\n",
    "            if dist <= max_distance:\n",
    "                matched = True\n",
    "                break\n",
    "\n",
    "        if not matched:\n",
    "            unmatched_new_rows.append(new_row)\n",
    "\n",
    "    # Prepend unmatched rows\n",
    "    if unmatched_new_rows:\n",
    "        prepend_df = pd.DataFrame(unmatched_new_rows)\n",
    "        master_df = pd.concat([prepend_df, master_df], ignore_index=True)\n",
    "\n",
    "    return master_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a9da0cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_horizontal_scroll(prev_df, curr_df):\n",
    "    prev_cols = list(prev_df.columns)\n",
    "    curr_cols = list(curr_df.columns)\n",
    "    print(f\"prev_cols = {prev_cols}\")\n",
    "    print(f\"curr_cols = {curr_cols}\")\n",
    "\n",
    "    prev_right_col = prev_cols[-1]\n",
    "    prev_left_col = prev_cols[0]\n",
    "    if prev_cols == curr_cols:\n",
    "        return None\n",
    "    elif prev_right_col in curr_cols[:-1]:\n",
    "        return \"right\"\n",
    "    elif prev_left_col in curr_cols[1:]:\n",
    "        return \"left\"\n",
    "    else:\n",
    "        return \"horizontal_shift\"  # unaligned but not single step\n",
    "\n",
    "\n",
    "\n",
    "numeric_cols = ['OVR', 'SPD', 'ACC', 'AGI', 'COD', 'STR', 'AWR', 'THP', 'SAC', 'MAC', 'DAC', 'RUN', 'TUP', 'BSK']\n",
    "# shift, score = detect_scroll_shift(arr_dfs_going_left[0], arr_dfs_going_left[2], numeric_cols, max_shift=5)\n",
    "# print(f\"Detected scroll: rows={shift[0]}, cols={shift[1]} | score={score}\")\n",
    "\n",
    "df_prev = arr_dfs_going_left[2]\n",
    "df_curr = arr_dfs_going_left[0]\n",
    "def detect_scroll(df_prev, df_curr):\n",
    "    if horizontal := detect_horizontal_scroll(df_prev, df_curr):\n",
    "        return horizontal\n",
    "    else:\n",
    "        row_shift, score = detect_scroll_shift(df_prev, df_curr, numeric_cols)\n",
    "        if row_shift > 0:\n",
    "            return \"down\"\n",
    "        elif row_shift < 0:\n",
    "            return \"up\"\n",
    "        else:\n",
    "            return \"No scroll detected\"\n",
    "\n",
    "detect_scroll(df_prev, df_curr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3df2fd5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
